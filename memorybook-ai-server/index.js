// index.js - Local AI + Face proxy server for MemoryBook 

const express = require("express");
const cors = require("cors");
const bodyParser = require("body-parser");
const axios = require("axios");

// ğŸ‘‰ import helpers that talk to Python face_api
const {
  detectFacesInList,
  registerFace,
  recognizeFace,
} = require("./face-service");

const app = express();
app.use(cors());
app.use(bodyParser.json({ limit: "20mb" }));

// ---- Ollama config (adjust if needed) ----
const OLLAMA_URL = process.env.OLLAMA_URL || "http://127.0.0.1:11434";
// DeepSeek ä¸“é—¨ç”¨æ¥â€œæ”¹å†™ + è¾“å‡º JSONâ€
const OLLAMA_TEXT_MODEL = "deepseek-r1:7b"; // for text-only caption helper
// è§†è§‰æ¨¡å‹åªè´Ÿè´£çœ‹å›¾æè¿°ï¼ˆä¸å†ç›´æ¥è¾“å‡º JSONï¼‰
const OLLAMA_VISION_MODEL = "llava-phi3:latest"; // for real image-based caption

// -------------------------
// Small helpers
// -------------------------
function countWords(str) {
  return String(str || "")
    .trim()
    .split(/\s+/)
    .filter(Boolean).length;
}

// ğŸ”¹ æœ€ç¨³å¥çš„ caption å‰ªè£ï¼šä¸åŠ å¥å­ã€ä¸æ”¹é£æ ¼ã€ä¸æˆªæ–­åŠå¥
function normalizeCaptionLength(caption, captionDraft) {
  let result = String(caption || captionDraft || "").trim();
  if (!result) return "";

  // ç»Ÿä¸€ç©ºç™½
  result = result.replace(/\s+/g, " ").trim();
  let words = countWords(result);

  const MAX_WORDS = 28; // æœ€å¤§å…è®¸å­—æ•°

  // 1ï¸âƒ£ å¦‚æœå­—æ•°åœ¨èŒƒå›´å†… â†’ å®Œå…¨ä¿ç•™ DeepSeek çš„è‡ªç„¶é£æ ¼
  if (words <= MAX_WORDS) return result;

  // 2ï¸âƒ£ å­—æ•°è¶…è¿‡ MAX_WORDS â†’ å…ˆç²—ç•¥æˆªåˆ° 28 ä¸ªè¯
  let tokens = result.split(/\s+/);
  let truncated = tokens.slice(0, MAX_WORDS).join(" ");

  // 3ï¸âƒ£ å°è¯•æ™ºèƒ½æ”¶å°¾ï¼šä¸è®©å¥å­æ–­åœ¨ä¸€åŠ
  const punctuations = [".", "!", "?", "ã€‚", "ï¼", "ï¼Ÿ"];
  let lastPuncIndex = -1;

  for (const p of punctuations) {
    const idx = truncated.lastIndexOf(p);
    if (idx > lastPuncIndex) lastPuncIndex = idx;
  }

  if (lastPuncIndex > 0) {
    truncated = truncated.slice(0, lastPuncIndex + 1);
  }

  return truncated.trim();
}

// ğŸ”¹ æŠŠç¬¬ä¸‰äººç§°å¼ºè¡Œæ”¹æˆç¬¬ä¸€äººç§°ï¼ˆé˜²æ­¢ â€œI watched as she â€¦â€ è¿™ç§ï¼‰
function enforceFirstPerson(caption) {
  let result = String(caption || "");

  // she / her â†’ I / my
  result = result.replace(/\b[Ss]he\b/g, "I");
  result = result.replace(/\bHer\b/g, "My");
  result = result.replace(/\bher\b/g, "my");

  // he / him ä¸€èˆ¬ä¸ä¼šå‡ºç°ï¼Œå‡ºç°å°±ç²—æš´å½“æˆ I / me
  result = result.replace(/\b[Hh]e\b/g, "I");
  result = result.replace(/\b[Hh]im\b/g, "me");

  return result;
}

// ğŸ”¹ plush ä¸“ç”¨ï¼šå¦‚æœ draft é‡Œå†™äº† plushï¼Œä½† caption å´è¯´ dog / cat / bear / bunny â†’ ç»Ÿç»Ÿæ”¹æˆ plush toy
const ANIMAL_WORDS_FOR_PLUSH = [
  "dog",
  "dogs",
  "puppy",
  "puppies",
  "cat",
  "cats",
  "kitten",
  "kittens",
  "bear",
  "bears",
  "bunny",
  "bunnies",
  "rabbit",
  "rabbits",
];

function fixPlushAnimalHallucination(caption, captionDraft) {
  const draftLower = String(captionDraft || "").toLowerCase();
  if (!draftLower.includes("plush")) return caption; // ç”¨æˆ·æ²¡æ plushï¼Œå°±ä¸è¦ä¹±æ”¹

  let result = String(caption || "");
  ANIMAL_WORDS_FOR_PLUSH.forEach((word) => {
    const re = new RegExp("\\b" + word + "\\b", "gi");
    result = result.replace(re, "plush toy");
  });
  return result;
}

// ğŸ”¹ Hashtag æœ€å°å¤„ç†ï¼šå»ç©ºã€å»é‡ã€å°å†™ã€è¿‡æ»¤æ•æ„Ÿè¯ã€æœ€å¤š 5 ä¸ª
const SENSITIVE_TAGS_REQUIRE_DRAFT = [
  "birthday",
  "cake",
  "cakes",
  "dessert",
  "desserts",
  "party",
  "celebration",
];

function adjustHashtags(hashtags, captionDraft) {
  let tags = Array.isArray(hashtags) ? [...hashtags] : [];

  tags = tags
    .map((t) => String(t).trim())
    .filter(Boolean)
    .map((t) => t.toLowerCase().replace(/\s+/g, ""));

  // å»é‡
  tags = Array.from(new Set(tags));

  // æ²¡æœ‰åœ¨ draft é‡Œæåˆ°çš„æ•æ„Ÿè¯ï¼Œç›´æ¥ ban æ‰ï¼ˆé¿å…å¹»è§‰è›‹ç³• / ç”Ÿæ—¥ï¼‰
  const draftLower = String(captionDraft || "").toLowerCase();
  tags = tags.filter((t) => {
    if (SENSITIVE_TAGS_REQUIRE_DRAFT.includes(t)) {
      return draftLower.includes(t);
    }
    return true;
  });

  return tags.slice(0, 5);
}

// ä¸æƒ³å‡ºç°åœ¨ caption é‡Œçš„ã€Œå¹»è§‰ç‰©ä»¶ã€
const BANNED_BACKGROUND_WORDS = [
  "matches",
  "matchbox",
  "box of matches",
  "pencil",
  "pencils",
  "pen",
  "pens",
  "marker",
  "markers",
  "notebook",
  "notebooks",
  "remote control",
  "remote",
];

// ä» caption é‡ŒæŠŠè¿™äº›è¯åˆ æ‰
function removeBannedWords(text) {
  let result = String(text || "");
  for (const w of BANNED_BACKGROUND_WORDS) {
    const re = new RegExp("\\b" + w.replace(/\s+/g, "\\s+") + "\\b", "ig");
    result = result.replace(re, "");
  }
  // å†æ•´ç†ç©ºç™½
  return result.replace(/\s+/g, " ").trim();
}

// -------------------------
// Helper: call Ollama (text â†’ DeepSeek)
// -------------------------
async function callOllamaChatText(prompt) {
  const resp = await axios.post(`${OLLAMA_URL}/api/chat`, {
    model: OLLAMA_TEXT_MODEL,
    messages: [{ role: "user", content: prompt }],
    // è®© DeepSeek ç›´æ¥ç»™ JSONï¼ˆå®ƒä¼šæŠŠ <think> æ”¶åœ¨å†…éƒ¨ï¼‰
    format: "json",
    stream: false,
  });

  const msg = resp.data?.message?.content || "";
  return msg;
}

// -------------------------
// Helper: Vision â€“ å•å¼ å›¾ç‰‡æè¿°ï¼ˆåŠ å¼ºç‰ˆï¼šè¯»æ‹›ç‰Œ + ç¦æ­¢å¹»æƒ³ï¼‰
// -------------------------
async function describeSingleImage(imageBase64, index, total) {
  if (!imageBase64) return "";

  const body = {
    model: OLLAMA_VISION_MODEL,
    messages: [
      {
        role: "user",
        content: `
You are a very strict vision model. This is photo ${index} of ${total}.
Describe ONLY what you clearly see in this one photo.

FOCUS (VERY IMPORTANT):
- Focus on the main subject (people, landscapes, buildings, plush toys, large objects).
- If there is any LARGE, CLEAR text on a sign, building, product, or sculpture
  (for example "BOH"), you MUST copy that text exactly once in your description,
  wrapped in quotes, like: the large white "BOH" sign on the hill.
- Completely ignore tiny or unclear background items, especially on tables or far away.
- If you are not 100% sure what an object is, DO NOT name it.
- If the main subject looks like a plush toy, and you are not 100% sure which animal it is,
  call it simply "a plush toy" or "a plush character", do NOT guess dog / cat / bear / bunny.

STRICT NO-GUESSING RULES:
- Do NOT talk about sounds (no "birds chirping", "music playing", etc.).
- Do NOT guess how many people are there if you cannot clearly count them.
- Do NOT invent activities like "people gathering around tables" unless the tables
  and people are clearly visible with chairs etc.
- Do NOT describe feelings or atmosphere ("inviting", "cozy", "romantic") â€”
  keep it purely visual.

STYLE:
- Use simple English, 1â€“2 short sentences.
- Mention key visible details of the main subject (shape, colors, text on signs).
- Do NOT mention "photo", "image", "camera" or "AI".
- Just give a neutral description of what is visible with your eyes.
`.trim(),
        images: [imageBase64],
      },
    ],
    stream: false,
  };

  const resp = await axios.post(`${OLLAMA_URL}/api/chat`, body);
  const msg = resp.data?.message?.content || "";
  return String(msg || "").trim();
}

// -------------------------
// Helper: Vision â€“ å¤šå¼ å›¾ç‰‡ï¼Œé€å¼ æè¿°å†åˆå¹¶
// -------------------------
async function callOllamaVisionDescribeMulti(imageBase64List, captionDraft) {
  const safeList = Array.isArray(imageBase64List)
    ? imageBase64List.filter(Boolean)
    : [];
  if (!safeList.length) return "";

  const total = safeList.length;
  const parts = [];

  for (let i = 0; i < total; i++) {
    try {
      const desc = await describeSingleImage(safeList[i], i + 1, total);
      if (desc) {
        parts.push(`Photo ${i + 1}: ${desc}`);
      }
    } catch (err) {
      console.log(
        `Vision describe error on photo ${i + 1}:`,
        err.message || err
      );
    }
  }

  if (!parts.length) return "";

  const combined = parts.join("\n");
  console.log("[VISION] Combined per-photo description:\n", combined);
  return combined;
}

// -------------------------
// /generatePostMeta  â€”â€” å¤šå›¾ç‰ˆæœ¬
// -------------------------
app.post("/generatePostMeta", async (req, res) => {
  try {
    const {
      captionDraft = "",
      imageBase64List = [],
      imageBase64 = null,
    } = req.body || {};

    const images =
      Array.isArray(imageBase64List) && imageBase64List.length > 0
        ? imageBase64List.filter(Boolean)
        : imageBase64
        ? [imageBase64]
        : [];

    console.log(
      "\nğŸ§  /generatePostMeta received. Images count:",
      images.length,
      "Draft:",
      captionDraft
    );

    // 1) Vision
    let visionDescription = "";
    if (images.length > 0) {
      try {
        visionDescription = await callOllamaVisionDescribeMulti(
          images,
          captionDraft
        );
        console.log(
          "[VISION] Description from llava (multi):",
          visionDescription
        );
      } catch (err) {
        console.log(
          "âš ï¸ Vision describe error, continue with text-only:",
          err.message || err
        );
      }
    }

    // 2) DeepSeek
    const systemInstruction = `
You are an assistant for a personal memory / social media app. 

You will receive:
- A short draft caption written by the user (may be empty).
- A neutral description of the photo(s) from another AI model (may be empty).

Your job is to:
1) Understand what is happening (people, place, objects, mood).
2) Write a warm, natural, first-person caption.
3) Suggest a few simple hashtags related ONLY to what you actually see.

GENERAL VISION RULES (VERY IMPORTANT):
- Treat everything as real life (no fantasy, no magic, no sci-fi).
- Only describe things that are clearly visible.
- If you are unsure about something, do NOT mention it.
- Do NOT exaggerate or invent:
  - Do NOT mention "friends", "we", "our group", "everyone" unless:
    â€¢ there are clearly TWO OR MORE people visible in the photos, OR
    â€¢ the USER draft explicitly mentions friends.
  - If there is exactly ONE clear face, treat it as a SOLO moment with "I / me / my".
  - Do NOT say "cafe", "restaurant", "local food spot" unless you clearly see:
    â€¢ an indoor dining area, OR tables + chairs + counter/menu/signs etc.
  - Do NOT say "lunch", "dinner", "breakfast" unless you clearly see a meal or food.
  - Do NOT say "trip", "travel", "holiday" unless there are obvious travel clues
    like luggage, landmarks, hotel, airplane view, or the user draft says it.
- When the background is unclear, keep the place description very neutral
  (e.g. "today", "this moment", "tonight", "here") instead of guessing.
- Never invent a story like "I woke up early" or "I spent the whole day with you guys"
  unless the user draft clearly says so.

CAPTION RULES (STYLE C: gentle, diary-like, suitable for everyone):
- Use only first person ("I", "me", "my", "we", "our").
- Forbidden words in the caption: "she", "her", "he", "him", and speaking directly to "you".
- The caption MUST feel like a note to myself, not a message to an audience.
- Absolutely do NOT speak to "you", "everyone", "guys", etc.
- Style: like a real person writing a short diary line:
  - warm, simple, slightly emotional or cute, but not dramatic.
  - suitable for any gender and any age.
- The caption should feel like I am gently describing this moment for myself.
- Length: roughly 8â€“20 words (shorter and simple is okay).
- 0â€“2 emojis only.
- Do NOT mention "photo", "picture", "image", "camera", or "AI".
- Do NOT include hashtags in the caption.

BIRTHDAY RULES:
- If description clearly shows birthday cake / candles / "Happy Birthday" text
  or number candles, caption MUST mention the birthday context.

HASHTAG RULES:
- Return 1â€“5 hashtags WITHOUT the "#" symbol.
- All hashtags must be directly related to objects in description.
- Only include food / drink / cafe / friends tags when description clearly supports them.
- All hashtags lowercase, no spaces, no spammy tags.

FRIEND TAG RULES:
- DO NOT invent names.
- DO NOT guess or create friend names.
- Only include names that the USER explicitly typed in the draft caption.
- Use first names only, no @ and no #.
- If the user did not provide names, return an empty array: friendTags: [].

EXTRA SAFETY RULE (VERY IMPORTANT):
- If the vision description mentions small background items like
  "matches", "box of matches", "pencils", "pens", "notebooks", "remote controls", etc.,
  you MUST ignore these words completely.
- They must NOT appear in the final caption or hashtags at all.

TEXT ON SIGNS:
- If the vision description contains quoted text from a sign or logo
  (for example "BOH"), you SHOULD mention this name once in either
  the caption or in one of the hashtags (or both), as long as it feels natural.

Return ONLY valid JSON, no explanation, no markdown fences:

{
  "caption": "string",
  "hashtags": ["tag1","tag2"],
  "friendTags": ["name1","name2"]
}
`.trim();

    const totalPhotos = images.length;

    const combinedPrompt = `${systemInstruction}

Total number of photos in this memory: ${totalPhotos}

User draft caption (may be empty):
"${captionDraft || "(empty)"}"

Neutral description of the photo(s) from a vision model (may be empty):
"${visionDescription || "(no description)"}"

Using BOTH the user draft and the description, generate the final caption and hashtags.
Always obey ALL the rules above.
`;

    let rawContent;
    try {
      rawContent = await callOllamaChatText(combinedPrompt);
    } catch (err) {
      console.error(
        "âš ï¸ Ollama DeepSeek error in /generatePostMeta, using fallback:",
        err.message || err
      );
      rawContent = JSON.stringify({
        caption: captionDraft || "",
        hashtags: [],
        friendTags: [],
      });
    }

    console.log("[VISION] Raw content from DeepSeek:", rawContent);

    // Try to parse JSON from DeepSeek output
    let parsed = { caption: captionDraft, hashtags: [], friendTags: [] };
    try {
      let cleanedStr = String(rawContent || "").trim();

      if (cleanedStr.startsWith("```")) {
        cleanedStr = cleanedStr.replace(/^```[a-zA-Z0-9]*\s*/, "");
        cleanedStr = cleanedStr.replace(/```$/, "").trim();
      }

      const firstBrace = cleanedStr.indexOf("{");
      const lastBrace = cleanedStr.lastIndexOf("}");
      if (firstBrace !== -1 && lastBrace !== -1) {
        cleanedStr = cleanedStr.slice(firstBrace, lastBrace + 1);
      }

      parsed = JSON.parse(cleanedStr);
    } catch (err) {
      console.log("âš ï¸ Failed to parse JSON from DeepSeek, using fallback:", err);
    }

    // Normalize raw model output
    let caption = String(parsed.caption || captionDraft || "").trim();
    let hashtags = Array.isArray(parsed.hashtags)
      ? parsed.hashtags.map((h) => String(h).trim()).filter(Boolean)
      : [];

    // å…ˆç¡¬è¿‡æ»¤æ‰æˆ‘ä»¬ä¸æƒ³è¦çš„å¹»è§‰è¯
    caption = removeBannedWords(caption);
    // å†å¼ºåˆ¶å˜æˆç¬¬ä¸€äººç§°
    caption = enforceFirstPerson(caption);
    // plush + dog/cat/bear/bunny â†’ plush toy
    caption = fixPlushAnimalHallucination(caption, captionDraft);

    // ---- ENFORCE MINIMAL RULES HERE ----
    caption = normalizeCaptionLength(caption, captionDraft);
    hashtags = adjustHashtags(hashtags, captionDraft);

    // âœ… åªæœ‰å½“ draft é‡Œæœ¬æ¥å°±æåˆ° birthdayï¼Œæ‰å¼ºåˆ¶åŠ  birthday hashtag
    if (
      caption.toLowerCase().includes("birthday") &&
      String(captionDraft || "").toLowerCase().includes("birthday")
    ) {
      if (!hashtags.includes("birthday")) {
        hashtags.unshift("birthday");
      }
    }

    // -------- Face recognition for friendTags --------
    let faceMatches = [];
    if (images.length > 0) {
      try {
        const faceResp = await recognizeFace(images[0]);
        faceMatches = Array.isArray(faceResp.matches) ? faceResp.matches : [];
        console.log("[VISION] Face matches for friend tags:", faceMatches);
      } catch (err) {
        console.log("Face recognition in /generatePostMeta failed:", err);
      }
    }

    const faceNames = faceMatches
      .map((m) => (m.name || "").trim())
      .filter(Boolean);

    const friendTagsMerged = Array.from(new Set(faceNames));

    const cleaned = {
      caption,
      hashtags,
      friendTags: friendTagsMerged,
    };

    console.log("[VISION] Cleaned content:", cleaned);
    res.json(cleaned);
  } catch (err) {
    console.error("âŒ Error in /generatePostMeta:", err);
    res.status(500).json({ error: "Failed to generate post meta" });
  }
});

// -------------------------
// /faces/detect
// -------------------------
app.post("/faces/detect", async (req, res) => {
  const { imageBase64List } = req.body || {};
  try {
    const result = await detectFacesInList(imageBase64List || []);
    res.json(result);
  } catch (err) {
    console.error("âŒ /faces/detect error:", err);
    res.status(500).json({ error: "Face detect failed" });
  }
});

// -------------------------
// /faces/register
// -------------------------
app.post("/faces/register", async (req, res) => {
  const { personId, name, imageBase64 } = req.body || {};
  if (!name || !imageBase64) {
    return res
      .status(400)
      .json({ error: "name and imageBase64 are required." });
  }

  try {
    const pyResp = await registerFace(name, imageBase64);
    console.log("âœ… /faces/register -> Python:", pyResp);

    res.json({
      ok: pyResp.ok !== false,
      personId: personId || null,
      name: pyResp.name || name,
      encodingsCount: pyResp.encodingsCount || 1,
    });
  } catch (err) {
    console.error("âŒ /faces/register proxy error:", err);
    res.status(500).json({ error: "Face register failed" });
  }
});

// -------------------------
// /faces/recognize
// -------------------------
app.post("/faces/recognize", async (req, res) => {
  const { imageBase64, threshold } = req.body || {};
  if (!imageBase64) {
    return res.status(400).json({ error: "imageBase64 is required." });
  }

  try {
    const pyResp = await recognizeFace(imageBase64, threshold);
    console.log("âœ… /faces/recognize -> Python:", pyResp);

    res.json({
      ok: pyResp.ok !== false,
      matches: Array.isArray(pyResp.matches) ? pyResp.matches : [],
    });
  } catch (err) {
    console.error("âŒ /faces/recognize proxy error:", err);
    res.status(500).json({ error: "Face recognize failed" });
  }
});

// -------------------------
// Start server
// -------------------------
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`Local AI server running at http://localhost:${PORT}`);
});
